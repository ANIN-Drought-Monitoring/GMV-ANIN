{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87287272",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0522cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from shapely.geometry import mapping\n",
    "import geopandas as gpd\n",
    "from rasterio.enums import Resampling\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "from calendar import monthrange\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf013cd",
   "metadata": {},
   "source": [
    "# Directories"
   ]
  },
{
  "cell_type": "code",
  "execution_count": 2,
  "id": "8ebfe71d",
  "metadata": {},
  "outputs": [],
  "source": [
    "import os\n\n",
    "# Set the base directory with an environment variable, fallback to a relative path\n",
    "main_dir = os.getenv('PROJECT_DIR', os.path.join(os.getcwd(), 'data', 'ANIN', 'Generating Indices', 'CDI'))\n\n",
    "# Path for FAPAR anomaly with crop mask\n",
    "FAPARa_path = os.path.join(main_dir, 'FAPAR_Anomaly_crop_mask', 'RT1')\n\n",
    "# Path for Soil Moisture Anomaly (SMA) data\n",
    "SMA_path = os.path.join(main_dir, 'SMA')\n\n",
    "# Path for SPI data with an optional environment variable for network paths\n",
    "SPI_path = os.getenv('SPI_PATH', os.path.join(main_dir, 'SPI', 'outputs'))\n\n",
    "# Path for AOI folder which has the shape file\n",
    "Boundary = os.path.join(main_dir, 'Boundary')\n\n",
    "# Print paths for verification\n",
    "print('Main Directory:', main_dir)\n",
    "print('FAPARa Path:', FAPARa_path)\n",
    "print('SMA Path:', SMA_path)\n",
    "print('SPI Path:', SPI_path)\n",
    "print('Boundary Path:', Boundary)\n"
  ]
},
  {
   "cell_type": "markdown",
   "id": "fb6df134",
   "metadata": {},
   "source": [
    "# FAPAR anomaly data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4adc87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dictionary to add FAPAR anomaly data\n",
    "# the key is the date \n",
    "FAPAR_a ={}\n",
    "# Looping through each tif file of FAPAR anomaly \n",
    "for image in os.listdir(FAPARa_path):\n",
    "    # Path for the tif file\n",
    "    path = os.path.join(FAPARa_path, image)\n",
    "    # Open the tif file as xarray\n",
    "    fapar = rxr.open_rasterio(path, masked = True)\n",
    "    # Extract the month from the name of the tif file\n",
    "    month = image[:-32]\n",
    "    # Extract the year from the name of the tif file\n",
    "    year = image[-32:-28]\n",
    "    # Put month and year together as string\n",
    "    m_y = month+year\n",
    "    # Convert the month and year to date formate,\n",
    "    # then to string to be the key in the dictionary\n",
    "    key = str(datetime.strptime(m_y, \"%B%Y\"))\n",
    "    # Append the tif file to the dictionary\n",
    "    # .sel(band =1) is added to have dataarray with only\n",
    "    # x and y dimensions to be the same as those for SPI\n",
    "    FAPAR_a[key]=fapar.sel(band=1)\n",
    "# The following lines is to reorder the dictionary based on the date\n",
    "# The order will be from the first date to the last date\n",
    "myKeys = list(FAPAR_a.keys())\n",
    "myKeys.sort()\n",
    "FAPAR_a = {i: FAPAR_a[i] for i in myKeys}\n",
    "# Take the crs of the project\n",
    "crs_project= fapar.rio.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c27945",
   "metadata": {},
   "source": [
    "# SMA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5ce1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty dictionary to add SMA data\n",
    "# the key is the date\n",
    "SMA={}\n",
    "# Looping through each tif file of SMA \n",
    "for image in os.listdir(SMA_path):\n",
    "    # Path for the tif file\n",
    "    path = os.path.join(SMA_path, image)\n",
    "    # Open the tif file as xarray\n",
    "    sma = rxr.open_rasterio(path, masked = True)\n",
    "    # Reproject SMA to match fapar\n",
    "    # Resampling to 300m as fapar using Bilinear method\n",
    "    sma = sma.rio.reproject_match(fapar, resampling= Resampling.bilinear)\n",
    "    # Extract the year and month from the name of the tif file\n",
    "    # and add them as key for the dictionary\n",
    "    key = str(datetime.strptime(image[:-4], \"%Y%m\"))\n",
    "    # Append the tif file to the dictionary\n",
    "    # .sel(band =1) is added to have dataarray with only\n",
    "    # x and y dimensions to be the same as those for SPI\n",
    "    SMA[key]=sma.sel(band=1)\n",
    "# The following lines is to reorder the dictionary based on the date\n",
    "# The order will be from the first date to the last date\n",
    "myKeys = list(SMA.keys())\n",
    "myKeys.sort()\n",
    "SMA = {i: SMA[i] for i in myKeys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "335328a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the netcdf file of SPI\n",
    "SPI_nc = rxr.open_rasterio(SPI_path +'\\\\'+'SPI.nc', masked=True)\n",
    "# Giving CRS\n",
    "SPI_nc.rio.write_crs(crs_project, inplace=True)\n",
    "# Empty dictionary to add SPI data\n",
    "# the key is the date\n",
    "SPI={}\n",
    "# 1980 is the start date for the time band of the netcdf file\n",
    "# the name of bands is the number of days after 1980\n",
    "# So start_datetime will be used as a reference to select \n",
    "# SPI for each month seperately\n",
    "start_datetime = datetime(1980,1,1,0,0,0) \n",
    "# Looping through days after 1980 which is as a list of \n",
    "# attribute 'NETCDF_DIM_time_VALUES'\n",
    "for d in SPI_nc.attrs['NETCDF_DIM_time_VALUES']:\n",
    "    # this to skip dates before July 2020 and after\n",
    "    # December 2022\n",
    "    if d<14792 or d>=15706:\n",
    "        continue\n",
    "    # Convert the days after 1980 to a date\n",
    "    date = start_datetime + timedelta(days =d)\n",
    "    # Select the SPI corresponds to this date\n",
    "    spi = SPI_nc.sel(time=date)\n",
    "    # Reproject SPI to match fapar\n",
    "    # Resampling to 300m as fapar using Bilinear method   \n",
    "    spi = spi.rio.reproject_match(fapar, resampling= Resampling.bilinear,nodata=np.nan)\n",
    "    # The key is the date\n",
    "    key = str(date)\n",
    "    # Append the tif file to the dictionary\n",
    "    SPI[key]=spi\n",
    "    \n",
    "# The following lines is to reorder the dictionary based on the date\n",
    "# The order will be from the first date to the last date \n",
    "myKeys = list(SPI.keys())\n",
    "myKeys.sort()\n",
    "SPI = {i: SPI[i] for i in myKeys}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b146c7e2",
   "metadata": {},
   "source": [
    "# CDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a551c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following lines is to add FAPAR anomaly,\n",
    "SMA, and SPI as three bands in an xarray\n",
    "'''\n",
    "# Empty dictionary to add CDI data\n",
    "# the key is the date\n",
    "CDI_stack ={}\n",
    "# Looping using keys for FAPAR anomaly data\n",
    "for i in FAPAR_a:\n",
    "    # FAPAR anomaly for the corresponding month\n",
    "    F = FAPAR_a[i]\n",
    "    # SMA for the corresponding month\n",
    "    # try and except to avoid missing months\n",
    "    try:\n",
    "        SM = SMA[i]\n",
    "    except:\n",
    "        continue\n",
    "    # SPI for the corresponding month\n",
    "    # try and except to avoid missing months\n",
    "    try:\n",
    "        SP = SPI[i]\n",
    "    except:\n",
    "        continue\n",
    "    # Concatenation of the three bands\n",
    "    concat =xr.concat([SP,SM,F], 'index')\n",
    "    # Append the tif file to the dictionary\n",
    "    CDI_stack[i]=concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b55254dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile loaded. To prepare for masking, run the function\n",
      "        `select_shape`.\n",
      "Mask created.\n"
     ]
    }
   ],
   "source": [
    "# Load the shapefile\n",
    "def load_shape_file(filepath):\n",
    "    \"\"\"Loads the shape file desired to mask a grid.\n",
    "    Args:\n",
    "        filepath: Path to *.shp file\n",
    "    \"\"\"\n",
    "    shpfile = gpd.read_file(filepath)\n",
    "    print(\"\"\"Shapefile loaded. To prepare for masking, run the function\n",
    "        `select_shape`.\"\"\")\n",
    "    return shpfile\n",
    "\n",
    "#Create the mask\n",
    "def select_shape(shpfile):\n",
    "\n",
    "    \"\"\"Select the submask of interest from the shapefile.\n",
    "    Args:\n",
    "        shpfile: (*.shp) loaded through `load_shape_file`\n",
    "        category: (str) header of shape file from which to filter shape.\n",
    "            (Run print(shpfile) to see options)\n",
    "        name: (str) name of shape relative to category.\n",
    "           Returns:\n",
    "        shapely polygon\n",
    "    \"\"\"\n",
    "\n",
    "    col_code = 'ISO3_CODE'\n",
    "    country_codes = ['ZAF', 'LSO', 'SWZ']\n",
    "\n",
    "    # Extract the rows that have 'ZAF', 'LSO', or 'SWZ' in the 'SOV_A3' column\n",
    "    selected_rows = shpfile[shpfile[col_code].isin(country_codes)]\n",
    "\n",
    "    # Combine the selected polygons into a single polygon\n",
    "    unioned_polygon = selected_rows.geometry.unary_union\n",
    "\n",
    "    # Convert the unioned polygon to a geopandas dataframe with a single row\n",
    "    mask_polygon = gpd.GeoDataFrame(geometry=[unioned_polygon])\n",
    "    \n",
    "    print(\"\"\"Mask created.\"\"\")\n",
    "\n",
    "    return mask_polygon\n",
    "shpfile = load_shape_file(Boundary + '\\\\'+ 'CNTR_RG_01M_2020_4326.shp')\n",
    "AOI = select_shape(shpfile)\n",
    "# Define a crs to the AOI \n",
    "AOI.crs =fapar.rio.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c650d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following lines are to use thresholds \n",
    "of FAPAR anomaly, SMA, and SPI to calculate CDI\n",
    "'''\n",
    "# This count is to skip the first month in the sequence\n",
    "# because there are some classes which need data from\n",
    "# previous month\n",
    "count =0\n",
    "# looping through stacks of data\n",
    "for i in CDI_stack:\n",
    "    # skip the first image\n",
    "    # but save it as i_1 to be used with the next month\n",
    "    if count ==0:\n",
    "        count =count+1\n",
    "        i_1 = i\n",
    "        continue\n",
    "    # Watch class: when SPI-3 is less than -1 and make no data as 0\n",
    "    CDI = xr.where(CDI_stack[i][0]<-1, 1, 0)\n",
    "    # Warning class: where SPI-3 < -1 and SMA < -1\n",
    "    CDI =xr.where((CDI_stack[i][1]<-1) & (CDI==1),2,CDI)\n",
    "    # Alert class: where SPI-3 < -1 and FAPAR anomaly < -1\n",
    "    CDI =xr.where((CDI_stack[i][2]<-1) & (CDI==1),3,CDI)\n",
    "    # Partial recovery:  where FAPAR anomaly < -1 and SPI-3 m-1 < -1 and SPI-3 > -1\n",
    "    CDI =xr.where((CDI_stack[i][2]<-1) & (CDI_stack[i][0]>-1) & (CDI_stack[i_1][0]<-1),4,CDI)\n",
    "    # Full recovery:  where FAPAR anomaly > -1 and SPI-3 m-1 < -1 and SPI-3 > -1\n",
    "    CDI =xr.where((CDI_stack[i][2]>-1) & (CDI_stack[i][0]>-1) & (CDI_stack[i_1][0]<-1),5,CDI)\n",
    "    # make no data as nan\n",
    "    CDI = CDI.where(CDI!=0)\n",
    "    # CRS\n",
    "    CDI= CDI.rio.write_crs(crs_project)\n",
    "    # Clipping to the AOI to delete pixels outside AOI which are few\n",
    "    clipped_CDI = CDI.rio.clip(AOI.geometry.apply(mapping),\n",
    "                                     crs=AOI.crs,\n",
    "                                     all_touched=True,\n",
    "                                     from_disk=True).squeeze()\n",
    "    # Export CDI as tif file\n",
    "    CDI.rio.to_raster(main_dir+'\\\\'+'CDI'+'\\\\'+i[:10] +'_CDI.tif')\n",
    "    # To save the stack of FAPAR anomaly, SPI, and SMA\n",
    "    # to be used for the following month\n",
    "    i_1 = i\n",
    "    # to avoid the if condition which is in the beginning \n",
    "    # of the loop\n",
    "    count =count+1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gis",
   "language": "python",
   "name": "gis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
