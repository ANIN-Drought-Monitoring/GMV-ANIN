{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "from pyproj import CRS\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "import climate_indices\n",
    "from climate_indices import indices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SETTING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################ SETTING PARAMETERS  for the SPI #################################################################\n",
    "\n",
    "scale = 3\n",
    "distribution = climate_indices.indices.Distribution.gamma   #Fixed\n",
    "data_start_year = 1980\n",
    "calibration_year_initial = 1980\n",
    "calibration_year_final = 2023\n",
    "periodicity = climate_indices.compute.Periodicity.monthly   #Fixed\n",
    "\n",
    "######################################################################################### CRS ############################################################################\n",
    "\n",
    "crs_project = CRS.from_epsg(4326) #WGS84\n",
    "\n",
    "######################################################################################### INPUTS ############################################################################\n",
    "\n",
    "ERA5_input_path = 'C:/ANIN/SPEI/data/ERA5_monthly.nc'\n",
    "ERA5_daily_input_folder = 'C:/ANIN/SPEI/data/DAILY' \n",
    "\n",
    "######################################################################################### OUPUTS ############################################################################\n",
    "\n",
    "path_out = \"C:/ANIN/SPEI/outputs/\"\n",
    "SPEI_ouput_file = \"SPEI3v2.nc\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MASK FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the shapefile\n",
    "def load_shape_file(filepath):\n",
    "    \"\"\"Loads the shape file desired to mask a grid.\n",
    "    Args:\n",
    "        filepath: Path to *.shp file\n",
    "    \"\"\"\n",
    "    shpfile = gpd.read_file(filepath)\n",
    "    print(\"\"\"Shapefile loaded. To prepare for masking, run the function\n",
    "        `select_shape`.\"\"\")\n",
    "    return shpfile\n",
    "\n",
    "#Create the mask\n",
    "def select_shape(shpfile):\n",
    "    \"\"\"Select the submask of interest from the shapefile.\n",
    "    Args:\n",
    "        shpfile: (*.shp) loaded through `load_shape_file`\n",
    "        category: (str) header of shape file from which to filter shape.\n",
    "            (Run print(shpfile) to see options)\n",
    "        name: (str) name of shape relative to category.\n",
    "           Returns:\n",
    "        shapely polygon\n",
    "    \"\"\"\n",
    "\n",
    "    col_code = 'ISO3_CODE'\n",
    "    country_codes = ['ZAF', 'LSO', 'SWZ']\n",
    "\n",
    "    # Extract the rows that have 'ZAF', 'LSO', or 'SWZ' in the 'SOV_A3' column\n",
    "    selected_rows = shpfile[shpfile[col_code].isin(country_codes)]\n",
    "\n",
    "    # Combine the selected polygons into a single polygon\n",
    "    unioned_polygon = selected_rows.geometry.unary_union\n",
    "\n",
    "    # Convert the unioned polygon to a geopandas dataframe with a single row\n",
    "    mask_polygon = gpd.GeoDataFrame(geometry=[unioned_polygon])\n",
    "    \n",
    "    print(\"\"\"Mask created.\"\"\")\n",
    "\n",
    "    return mask_polygon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MASK LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefile loaded. To prepare for masking, run the function\n",
      "        `select_shape`.\n",
      "Mask created.\n"
     ]
    }
   ],
   "source": [
    "#Load de shp\n",
    "shpfile = load_shape_file('C:/ANIN/clip_layer/CNTR_RG_01M_2020_4326.shp')\n",
    "\n",
    "#Create the mask layer\n",
    "mask_layer = select_shape(shpfile)\n",
    "\n",
    "#Giving a CRS\n",
    "mask_layer.crs = crs_project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VARIABLE PROCESSING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ERA5 TEMPERATURE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_temp_files = glob.glob(os.path.join(ERA5_daily_input_folder, '*.nc'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTemperaturesData(temp_data):\n",
    "    \"\"\"Process the data to get daily max, mean and min temperatures as input to the SPEI function\n",
    "    Args:\n",
    "        data: netcdf file with hourly temperature data\n",
    "\n",
    "        Returns\n",
    "        Three dataarray for Tmax, Tmin and Tmean with monthly values\n",
    "    \"\"\"  \n",
    "    temp_data = (temp_data * 0.0008411010185231105) + 289.25556089480324 #Rescaling the values\n",
    "\n",
    "    #Create 3 variables for daily tmax, tmin and tmean\n",
    "    temp_tmax = temp_data.resample(time ='D').max()-273.15\n",
    "    temp_tmin = temp_data.resample(time ='D').min()-273.15\n",
    "    temp_tmean = temp_data.resample(time ='D').mean()-273.15\n",
    "\n",
    "    # Resample data from daily into monthly. \n",
    "    temp_tmax = temp_tmax.resample(time ='M').mean()\n",
    "    temp_tmin = temp_tmin.resample(time ='M').mean()\n",
    "    temp_tmean = temp_tmean.resample(time ='M').mean()\n",
    "\n",
    "    # Resample original data from hourly into monthly to have the structure\n",
    "    temperatures = temp_data.resample(time='M').mean()\n",
    "\n",
    "    #Putting all together\n",
    "    temperatures['tmax'] = temp_tmax\n",
    "    temperatures['tmin'] = temp_tmin\n",
    "    temperatures['tmean'] = temp_tmean\n",
    "\n",
    "    #Separate in variables\n",
    "    tmax = temperatures['tmax']\n",
    "    tmax = tmax.drop_vars(['tmin', 'tmean'])\n",
    "    tmax = tmax.reindex(y=list(reversed(tmax['y'])))    # Reverse the Y dimension values to increasing values (This is an issue of ERA5 datasets and other climatic datasets)\n",
    "    tmax.rio.write_crs(crs_project, inplace=True)\n",
    "\n",
    "    tmean = temperatures['tmean']\n",
    "    tmean = tmean.drop_vars(['tmin', 'tmax'])\n",
    "    tmean = tmean.reindex(y=list(reversed(tmean['y']))) # Reverse the Y dimension values to increasing values (This is an issue of ERA5 datasets and other climatic datasets)\n",
    "    tmean.rio.write_crs(crs_project, inplace=True)\n",
    "\n",
    "    tmin = temperatures['tmin']\n",
    "    tmin = tmin.drop_vars(['tmax', 'tmean'])\n",
    "    tmin = tmin.reindex(y=list(reversed(tmin['y'])))    # Reverse the Y dimension values to increasing values (This is an issue of ERA5 datasets and other climatic datasets)\n",
    "    tmin.rio.write_crs(crs_project, inplace=True)\n",
    "\n",
    "    #Mask the country\n",
    "    tmax_masked = tmax.rio.clip(mask_layer.geometry.apply(mapping), crs=mask_layer.crs, all_touched=True, from_disk=True).squeeze()\n",
    "    tmean_masked = tmean.rio.clip(mask_layer.geometry.apply(mapping), crs=mask_layer.crs, all_touched=True, from_disk=True).squeeze()\n",
    "    tmin_masked = tmin.rio.clip(mask_layer.geometry.apply(mapping), crs=mask_layer.crs, all_touched=True, from_disk=True).squeeze()\n",
    "\n",
    "    return tmax_masked, tmean_masked, tmin_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_list = []\n",
    "tmin_list = []\n",
    "tmean_list = []\n",
    "\n",
    "#Applying the function to each one of the files with hourly data. Appending the result in separate variable lists\n",
    "for file in daily_temp_files:\n",
    "    data = rxr.open_rasterio(file, masked=True)\n",
    "    tmax_masked, tmean_masked, tmin_masked = getTemperaturesData(data)\n",
    "    tmax_list.append(tmax_masked)\n",
    "    tmean_list.append(tmean_masked)\n",
    "    tmin_list.append(tmin_masked)\n",
    "\n",
    "#Creating an xarray for each temp variable\n",
    "Tmax = xr.concat(tmax_list, dim='time')\n",
    "Tmean = xr.concat(tmean_list, dim='time')\n",
    "Tmin = xr.concat(tmin_list, dim='time')\n",
    "\n",
    "#Changing time format\n",
    "Tmax['time'] = Tmax['time'].astype('datetime64[ns]')\n",
    "Tmean['time'] = Tmean['time'].astype('datetime64[ns]')\n",
    "Tmin['time'] = Tmin['time'].astype('datetime64[ns]')\n",
    "\n",
    "#Cleaning\n",
    "Tmax = Tmax.drop_vars('tmax')\n",
    "Tmean = Tmean.drop_vars('tmean')\n",
    "Tmin = Tmin.drop_vars('tmin')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ERA5 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "data = rxr.open_rasterio(ERA5_input_path, masked=True)\n",
    "#Giving a CRS\n",
    "data.rio.write_crs(crs_project, inplace=True)\n",
    "data['time'] = data['time'].astype('datetime64[ns]')  # Change to datetime format to fix with te temp data ahead\n",
    "\n",
    "data = data.assign_coords(time=pd.to_datetime(data.time.values) + pd.offsets.MonthEnd(1))   #Change the firt day of the month for the last day of the month\n",
    "#data = data.sel(time=slice('1980', '1989'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract and give shape to the precipitation data\n",
    "def getPrecipData(precip_data):\n",
    "    \"\"\"Process the data to get precipitation as input to the SPEI function\n",
    "    Args:\n",
    "        data: netcdf file with precip data\n",
    "\n",
    "        Returns\n",
    "        DataArrayGroupBy grouped over point (y and x coordinates)\n",
    "    \"\"\"\n",
    "    num_days_month = precip_data.time.dt.days_in_month #Necessary to multiply the daily values of the mean to the \"size\" of the month\n",
    "\n",
    "    precip = (precip_data * 2.908522800670776e-07) + 0.009530702520736942 #Rescaling the values\n",
    "    precip = precip*1000*num_days_month  # The original units are meters, we change them to milimeters, and multiply by the days of the month\n",
    "    \n",
    "# Reverse the Y dimension values to increasing values (This is an issue of ERA5 datasets and other climatic datasets)\n",
    "    precip = precip.rename({'y': 'lat', 'x':'lon'})       #Necessary step\n",
    "    precip = precip.reindex(lat=list(reversed(precip['lat'])))\n",
    "    precip = precip.rename({'lat': 'y', 'lon':'x'})\n",
    "\n",
    "#Mask the country\n",
    "    precip_masked = precip.rio.clip(mask_layer.geometry.apply(mapping), crs=mask_layer.crs, all_touched=True, from_disk=True).squeeze()\n",
    "\n",
    "#Giving the appropriate shape to da data\n",
    "    precip_grouped = precip_masked.stack(point=('y', 'x')).groupby('point')\n",
    "    print(\"\"\"Precipitation data is prepared to serve\n",
    "        as input for the SPEI index.\"\"\")\n",
    "\n",
    "    return precip_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precipitation data is prepared to serve\n",
      "        as input for the SPEI index.\n"
     ]
    }
   ],
   "source": [
    "#Get precipitation data\n",
    "precip_data = data['tp']\n",
    "precips_mm = getPrecipData(precip_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Surface solar radiation downwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSSRDdata(ssrd_data):\n",
    "    \"\"\"Process the data to get ssrd as input to the SPEI function\n",
    "    Args:\n",
    "        data: netcdf file with ssrd data\n",
    "\n",
    "        Returns\n",
    "        DataArray with ssrd data)\n",
    "    \"\"\"    \n",
    "    \n",
    "    ssrd = (ssrd_data * 401.7449529244808) + 20805007.127523538 #Rescaling the values\n",
    "    ssrd = ssrd * pow(10, -6)   # The original units are J/m2, we change them to MJ/m2\n",
    "\n",
    "# Reverse the Y dimension values to increasing values (This is an issue of ERA5 datasets and other climatic datasets)\n",
    "    ssrd = ssrd.rename({'y': 'lat', 'x':'lon'})       #Necessary step\n",
    "    ssrd = ssrd.reindex(lat=list(reversed(ssrd['lat'])))\n",
    "    ssrd = ssrd.rename({'lat': 'y', 'lon':'x'})\n",
    "\n",
    "#Mask the country\n",
    "    ssrd_masked = ssrd.rio.clip(mask_layer.geometry.apply(mapping), crs=mask_layer.crs, all_touched=True, from_disk=True).squeeze()\n",
    "\n",
    "    print(\"\"\"ssrd data is prepared to serve\n",
    "        as input for the SPEI index.\"\"\")\n",
    "\n",
    "    return ssrd_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssrd data is prepared to serve\n",
      "        as input for the SPEI index.\n"
     ]
    }
   ],
   "source": [
    "# Rn - net radiation at the crop surface MJ m-2 day-1\n",
    "ssrd_data = data['ssrd']\n",
    "Rn = getSSRDdata(ssrd_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dewpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getD2Mdata(d2m_data):\n",
    "    \"\"\"Process the data to get dewpoint temperature as input to the SPEI function\n",
    "    Args:\n",
    "        data: netcdf file with ssrd data\n",
    "\n",
    "        Returns\n",
    "        DataArray with temp dewpoint data\n",
    "    \"\"\"    \n",
    "\n",
    "    d2m = (d2m_data * 0.0005415367126581264) + 278.3172341144562 #Rescaling the values\n",
    "    d2m = d2m - 273.15   # The original units are K, we change them to ºC\n",
    "\n",
    "# Reverse the Y dimension values to increasing values (This is an issue of ERA5 datasets and other climatic datasets)\n",
    "    d2m = d2m.rename({'y': 'lat', 'x':'lon'})       #Necessary step\n",
    "    d2m = d2m.reindex(lat=list(reversed(d2m['lat'])))\n",
    "    d2m = d2m.rename({'lat': 'y', 'lon':'x'})\n",
    "\n",
    "#Mask the country\n",
    "    d2m_masked = d2m.rio.clip(mask_layer.geometry.apply(mapping), crs=mask_layer.crs, all_touched=True, from_disk=True).squeeze()\n",
    "\n",
    "    print(\"\"\"Dewpoint data is prepared to serve\n",
    "        as input for the SPEI index.\"\"\")\n",
    "\n",
    "    return d2m_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dewpoint data is prepared to serve\n",
      "        as input for the SPEI index.\n"
     ]
    }
   ],
   "source": [
    "#Dewpoint at 2 m height ºC\n",
    "d2m_data = data['d2m']\n",
    "Tdew = getD2Mdata(d2m_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Atmospheric pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSPdata(sp_data):\n",
    "    \"\"\"Process the data to get atmospheric pressure as input to the SPEI function\n",
    "    Args:\n",
    "        data: netcdf file with ssrd data\n",
    "\n",
    "        Returns\n",
    "        DataArray with atmospheric pressure data\n",
    "    \"\"\"    \n",
    "    sp = (sp_data * 0.4743678757267331) + 87188.76281606214 #Rescaling the values\n",
    "    sp = sp * (pow(10, -3))   # The original units are Pa, we change them to KPa\n",
    "\n",
    "# Reverse the Y dimension values to increasing values (This is an issue of ERA5 datasets and other climatic datasets)\n",
    "    sp = sp.rename({'y': 'lat', 'x':'lon'})       #Necessary step\n",
    "    sp = sp.reindex(lat=list(reversed(sp['lat'])))\n",
    "    sp = sp.rename({'lat': 'y', 'lon':'x'})\n",
    "\n",
    "#Mask the country\n",
    "    sp_masked = sp.rio.clip(mask_layer.geometry.apply(mapping), crs=mask_layer.crs, all_touched=True, from_disk=True).squeeze()\n",
    "\n",
    "    print(\"\"\"atmospheric pressure data is prepared to serve\n",
    "        as input for the SPEI index.\"\"\")\n",
    "\n",
    "    return sp_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atmospheric pressure data is prepared to serve\n",
      "        as input for the SPEI index.\n"
     ]
    }
   ],
   "source": [
    "#atmospheric pressure kPa\n",
    "sp_data = data['sp']\n",
    "P = getSPdata(sp_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWindData(u10, v10):\n",
    "    \"\"\"Process the data to get the wind component as input to the SPEI function\n",
    "    Args:\n",
    "        data: netcdf file with ssrd data\n",
    "\n",
    "        Returns\n",
    "        DataArray with wind data data\n",
    "    \"\"\"    \n",
    "    u10 = (u10 * 0.00013396971091090765) - 0.6710555445783558 #Rescaling the values of u10\n",
    "    v10 = (v10 * 0.00017109205086388073) + 1.4564011559399002 #Rescaling the values of v10\n",
    "\n",
    "    u2 = ((u10**2) + (v10**2))**0.5  # Getting wind component\n",
    "\n",
    "# Reverse the Y dimension values to increasing values (This is an issue of ERA5 datasets and other climatic datasets)\n",
    "    u2 = u2.rename({'y': 'lat', 'x':'lon'})       #Necessary step\n",
    "    u2 = u2.reindex(lat=list(reversed(u2['lat'])))\n",
    "    u2 = u2.rename({'lat': 'y', 'lon':'x'})\n",
    "\n",
    "#Mask the country\n",
    "    u2_masked = u2.rio.clip(mask_layer.geometry.apply(mapping), crs=mask_layer.crs, all_touched=True, from_disk=True).squeeze()\n",
    "\n",
    "    print(\"\"\"Wind data is prepared to serve\n",
    "        as input for the SPEI index.\"\"\")\n",
    "\n",
    "    return u2_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wind data is prepared to serve\n",
      "        as input for the SPEI index.\n"
     ]
    }
   ],
   "source": [
    "#u2 wind speed at 2 m height m s-1\n",
    "u10 = data['u10']\n",
    "v10 = data['v10']\n",
    "\n",
    "u2 = getWindData(u10, v10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Soil heat flux density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G -  soil heat flux density MJ m-2 day-1  Fixed value\n",
    "G = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ERA5-land variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#es saturation vapour pressure kPa\n",
    "def get_es(Tmax, Tmin):\n",
    "    e0Tmax = 0.6108 * np.exp((17.27*Tmax) / (Tmax + 237.3))\n",
    "    e0Tmin = 0.6108 * np.exp((17.27*Tmin) / (Tmin + 237.3))\n",
    "\n",
    "    es = (e0Tmax - e0Tmin) / 2\n",
    "\n",
    "    return es\n",
    "\n",
    "#ea actual vapour pressure kPa\n",
    "def get_ea(Tdew):\n",
    "    ea = 0.6108 * np.exp((17.27*Tdew) / (Tdew + 237.3))\n",
    "\n",
    "    return ea\n",
    "\n",
    "#slope vapour pressure curve kPa °C-1\n",
    "def get_svpc(Tmean):\n",
    "    svpc = (4098 * (0.6108 * np.exp((17.27*Tmean) / (Tmean + 237.3)))) / ((Tmean + 237.3)**2)\n",
    "\n",
    "    return svpc\n",
    "\n",
    "#Psychometric constant\n",
    "def get_psi_cnt(P):\n",
    "    Cp = 0.001013   #specific heat at constant pressure MJ kg-1 °C-1\n",
    "    epsi = 0.622    #ratio molecular weight of water vapour/dry air\n",
    "    lamb = 2.45     #latent heat of vaporization MJ kg-1\n",
    "\n",
    "    psi_cnt = (Cp * P) / (epsi * lamb)\n",
    "\n",
    "    return psi_cnt\n",
    "\n",
    "# ET0 function\n",
    "def get_pet_mm(svpc, Rn, G, psi_cnt, Tmean, u2, es, ea):\n",
    "    pet_mm = (((0.408 * svpc) * (Rn - G)) + (psi_cnt * (900 / (Tmean + 273))) * u2 * (es - ea)) / (svpc + (psi_cnt * (1 + (0.34*u2))))\n",
    "    \n",
    "    return pet_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the components\n",
    "es = get_es(Tmax, Tmin)\n",
    "ea = get_ea(Tdew)\n",
    "svpc = get_svpc(Tmean)\n",
    "psi_cnt = get_psi_cnt(P)\n",
    "\n",
    "#Calculation pet\n",
    "pet_mm = get_pet_mm(svpc, Rn, G, psi_cnt, Tmean, u2, es, ea)\n",
    "\n",
    "#Giving the appropriate shape to da data. Grouping\n",
    "pet_mm_grouped = pet_mm.stack(point=('y', 'x')).groupby('point')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APPLY SPEI FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####https://github.com/monocongo/climate_indices\n",
    "spei_values = xr.apply_ufunc(indices.spei,\n",
    "                            precips_mm,\n",
    "                            pet_mm_grouped, \n",
    "                            scale,\n",
    "                            distribution,\n",
    "                            periodicity,\n",
    "                            data_start_year,\n",
    "                            calibration_year_initial,\n",
    "                            calibration_year_final\n",
    "                            )                 \n",
    "\n",
    "# Unstack the array back into original dimensions\n",
    "spei_results = spei_values.unstack('point')         \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPORTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spei_results.to_netcdf(f'{path_out}{SPEI_ouput_file}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4213db1b92f27a0df3bdb0f8c208fc37d0294f1bbcda358f5217b3f00267894"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
