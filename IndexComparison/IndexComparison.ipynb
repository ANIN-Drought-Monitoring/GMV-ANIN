{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import rioxarray as rio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping\n",
    "import rasterstats\n",
    "from rasterio.features import rasterize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import boundaries for spatial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the shapefile\n",
    "shapefile_path = '//gmvstorage.gmv.es/storage/anin/Groundwater/2011 Freshwater Ecosystem Priority Areas 9 Water Management Areas/9WMA.shp'\n",
    "areas = gpd.read_file(shapefile_path)\n",
    "areas = areas.set_crs('EPSG:4326')\n",
    "# Field in the shapefile table of attributes to be used for the averaging of the SGI in this case  \"SECONDARY\" for secondary catchments\n",
    "grouping_field = 'WMA_NewID' \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read SPEI and SPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fN_spei = \"//gmvstorage.gmv.es/storage/anin/SPEI/outputs/SPEI3.nc\"\n",
    "fN_spi= \"//gmvstorage.gmv.es/storage/anin/SPI/outputs/SPI.nc\"\n",
    "\n",
    "spei = xr.open_dataset(fN_spei)\n",
    "spi = xr.open_dataset(fN_spi)\n",
    "\n",
    "# Select time range matching the available GWL observations.\n",
    "start_date = \"1999-10-01\"\n",
    "end_date = \"2022-07-01\"\n",
    "\n",
    "spei = spei.sel(time=slice(start_date, end_date))\n",
    "spei= spei.rio.write_crs(4326, inplace=True)\n",
    "spei = spei.rename({'__xarray_dataarray_variable__': 'spei'})\n",
    "\n",
    "spi = spi.sel(time=slice(start_date, end_date))\n",
    "spi = spi.rio.write_crs(4326, inplace=True)\n",
    "spi = spi.rename({'__xarray_dataarray_variable__': 'spi'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rasterize the shapefile to be able to perform zonal statistics over rasterized data (ERA5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shapes = ((geom, value) for geom, value in zip(areas.geometry, areas['WMA_NewID']))\n",
    "\n",
    "eco_regions = rasterize(\n",
    "    shapes=shapes,\n",
    "    out_shape=(len(spi.y.data), len(spi.x.data)),\n",
    "    transform=spi.rio.transform(),\n",
    "    default_value=0,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Zonal Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arraylist_to_dataframe(array_list):\n",
    "    data = {}\n",
    "\n",
    "    # Iterate over the array_list and assign each array to a column in the dictionary\n",
    "    for i, array in enumerate(array_list):\n",
    "        column_name = f'Ecoregion{i+1}'\n",
    "        data[column_name] = array\n",
    "\n",
    "    # Create the DataFrame from the dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eco_spi = []\n",
    "eco_spei= []\n",
    "\n",
    "for id_basin in areas['WMA_NewID']:\n",
    "\n",
    "    spi_aux = spi.spi.data[:, eco_regions==id_basin]\n",
    "    spi_mean = np.nanmean(spi_aux,axis=1)\n",
    "    eco_spi.append(spi_mean)\n",
    "\n",
    "    spei_aux = spei.spei.data[:, eco_regions==id_basin]\n",
    "    spei_mean = np.nanmean(spei_aux,axis=1)\n",
    "    eco_spei.append(spei_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The parameter \"keys\" may be a column key, one-dimensional array, or a list containing only valid column keys and one-dimensional arrays.. Received column of type <class 'xarray.core.dataarray.DataArray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ecig\\Anaconda3\\envs\\geoTools\\lib\\site-packages\\pandas\\core\\frame.py:5999\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   5998\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 5999\u001b[0m     found \u001b[39m=\u001b[39m col \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\n\u001b[0;32m   6000\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ecig\\Anaconda3\\envs\\geoTools\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5332\u001b[0m, in \u001b[0;36mIndex.__contains__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5298\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5299\u001b[0m \u001b[39mReturn a boolean indicating whether the provided key is in the index.\u001b[39;00m\n\u001b[0;32m   5300\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5330\u001b[0m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   5331\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 5332\u001b[0m \u001b[39mhash\u001b[39;49m(key)\n\u001b[0;32m   5333\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'DataArray'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ecig\\Documents\\Python Scripts\\anin_git\\drought-indices\\IndexComparison\\IndexComparison.ipynb Cell 11\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ecig/Documents/Python%20Scripts/anin_git/drought-indices/IndexComparison/IndexComparison.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_spi \u001b[39m=\u001b[39m list_to_dataframe(eco_spi)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ecig/Documents/Python%20Scripts/anin_git/drought-indices/IndexComparison/IndexComparison.ipynb#X60sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_spi\u001b[39m.\u001b[39;49mset_index(spi\u001b[39m.\u001b[39;49mtime,inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ecig/Documents/Python%20Scripts/anin_git/drought-indices/IndexComparison/IndexComparison.ipynb#X60sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m df_spei \u001b[39m=\u001b[39m list_to_dataframe(eco_spei)\n",
      "File \u001b[1;32mc:\\Users\\ecig\\Anaconda3\\envs\\geoTools\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ecig\\Anaconda3\\envs\\geoTools\\lib\\site-packages\\pandas\\core\\frame.py:6001\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   5999\u001b[0m     found \u001b[39m=\u001b[39m col \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   6000\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 6001\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   6002\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00merr_msg\u001b[39m}\u001b[39;00m\u001b[39m. Received column of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(col)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   6003\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   6004\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6005\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m found:\n",
      "\u001b[1;31mTypeError\u001b[0m: The parameter \"keys\" may be a column key, one-dimensional array, or a list containing only valid column keys and one-dimensional arrays.. Received column of type <class 'xarray.core.dataarray.DataArray'>"
     ]
    }
   ],
   "source": [
    "df_spi = arraylist_to_dataframe(eco_spi)\n",
    "df_spei = arraylist_to_dataframe(eco_spei)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import GWL stations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and metadata\n",
    "\n",
    "# Load Metadata \n",
    "metadata_path = \"//gmvstorage.gmv.es/storage/anin/Groundwater/processed_data/stations_metadadata22_active.xlsx\"\n",
    "meta_df = pd.read_excel(metadata_path)\n",
    "meta_df.set_index('Station',inplace=True)\n",
    "\n",
    "# Select the columns that are necessary for this code\n",
    "meta_df = meta_df.iloc[:, 0:2]\n",
    "\n",
    "# Load data\n",
    "df_path = \"//gmvstorage.gmv.es/storage/anin/Groundwater/processed_data/stations_data22_active.xlsx\"\n",
    "df = pd.read_excel(df_path)\n",
    "df = df.iloc[:,1:]\n",
    "df.set_index('date',inplace=True)\n",
    "\n",
    "# Create a pandas time series for the plot function to work\n",
    "dates = pd.to_datetime(df.index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the SGI for all the stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modified sgi function which includes scaling \n",
    "from sgi_tools import compute_sgi\n",
    "\n",
    "# Define groundwater index scale factor\n",
    "scale = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to store the SGI values\n",
    "df_sgi = pd.DataFrame()\n",
    "\n",
    "# Apply the SGI function to each column of the DataFrame\n",
    "\n",
    "for column in df.columns:\n",
    "    df_sgi[column] = compute_sgi(df[column],scale)\n",
    "\n",
    "# Reset the index & Transpose the DataFrame\n",
    "dates = df_sgi.index.to_pydatetime()\n",
    "df_sgi = df_sgi.reset_index(drop = True)\n",
    "df_sgi = df_sgi.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform the average of the SGI values at each timestep for each catchment in the shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Join with coordinate information in metadata dataframe\n",
    "df_latlon = df_sgi.join(meta_df)\n",
    "\n",
    "# Convert the stations dataframe into a GeoDataFrame by specifying the geometry column with the coordinates:\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df_latlon['Longitude'], df_latlon['Latitude'])]\n",
    "stations_gdf = gpd.GeoDataFrame(df_latlon, geometry=geometry)\n",
    "\n",
    "# Perform a spatial join between the polygons and the stations to determine which stations fall within each polygon:\n",
    "stations_by_polygon = gpd.sjoin(areas, stations_gdf, how='inner', op='contains')\n",
    "\n",
    "# Select the columns based on their numeric names\n",
    "time_step_columns = [col for col in stations_by_polygon.columns if str(col).isdigit()]\n",
    "\n",
    "# Group the stations by polygon and time step, and calculate the average for each group:\n",
    "sgi_averages = stations_by_polygon.groupby([grouping_field])[time_step_columns].mean()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoTools",
   "language": "python",
   "name": "geotools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
